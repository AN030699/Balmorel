{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import datetime\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data from User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Market analysed: 'Investment','FullYear','DayAhead','Balancing' (choose one or several)\n",
    "market_analysed=['DayAhead','Balancing'] \n",
    "output='CurtailmentHourly'\n",
    "first_timestep=\"2012-01-02\"\n",
    "#Number of timesteps (total number of combination of SSS and TTT)\n",
    "number_periods=8736*12 \n",
    "#Time size of each time step for creating timestamp\n",
    "size_timestep=\"300s\"\n",
    "#Time size of each TTT calculating energy values\n",
    "size_t=1/12;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plotting specifications\n",
    "% matplotlib inline\n",
    "plt.rcParams.update({'font.size': 21})\n",
    "plt.rcParams['xtick.major.pad']='12'\n",
    "plt.rc('legend', fontsize=16)\n",
    "y_limit = 1.1\n",
    "lw = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Input Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.DataFrame()\n",
    "for market in market_analysed:\n",
    "    csvfiles = []\n",
    "    for file in glob.glob(\"./input/results/\" + market + \"/*.csv\"):\n",
    "        csvfiles.append(file)\n",
    "\n",
    "    csvfiles=[file.replace('./input\\\\','') for file in csvfiles] \n",
    "    csvfiles=[file.replace('.csv','') for file in csvfiles]  \n",
    "    csvfiles=[file.split('_') for file in csvfiles]  \n",
    "    csvfiles = np.asarray(csvfiles)  \n",
    "    csvfiles=pd.DataFrame.from_records(csvfiles)\n",
    "    \n",
    "    csvfiles.rename(columns={0: 'Output', 1: 'Scenario',2: 'Year',3:'Subset'}, inplace=True)\n",
    "    scenarios=csvfiles.Scenario.unique().tolist()\n",
    "    years=csvfiles.Year.unique().tolist()\n",
    "    subsets=csvfiles.Subset.unique().tolist()\n",
    "\n",
    "    for scenario in scenarios:\n",
    "        for year in years:\n",
    "            for subset in subsets:\n",
    "                file = \"./input/results/\"+ market + \"/\"+ output + \"_\" + scenario + \"_\" + year + \"_\" + subset + \".csv\"\n",
    "                if os.path.isfile(file):\n",
    "                    df=pd.read_csv(file,encoding='utf8')\n",
    "                    df['Scenario'] = scenario\n",
    "                    df['Market']   = market\n",
    "                    data=data.append(df) \n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for market in market_timestep_proc:\n",
    "    df_copy=data.loc[data.Market == market]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Converting timesteps\n",
    "if SSS_TTT_consistent==0:\n",
    "    data['SSS_NEW']=data['SSS']+data['TTT']\n",
    "    data['TTT_NEW']=data['SSS']+data['TTT']\n",
    "    dict_timesteps_conversion_SSS=pd.read_csv('./input/timesteps_conversion_SSS.csv', index_col=0, squeeze=True).to_dict()\n",
    "    dict_timesteps_conversion_TTT=pd.read_csv('./input/timesteps_conversion_TTT.csv', index_col=0, squeeze=True).to_dict()\n",
    "# and replace in the corresponding column\n",
    "    data['SSS_NEW']=data['SSS_NEW'].map(dict_timesteps_conversion_SSS)\n",
    "    data['TTT_NEW']=data['TTT_NEW'].map(dict_timesteps_conversion_TTT)\n",
    "    data.SSS_NEW.fillna(data.SSS, inplace = True) \n",
    "    data.TTT_NEW.fillna(data.TTT, inplace = True) \n",
    "# and cleaning data\n",
    "    del data['SSS']\n",
    "    del data['TTT']                                 \n",
    "    data.rename({'SSS_NEW': 'SSS', 'TTT_NEW': 'TTT'}, axis=1, inplace=True) \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Timestamp addition\n",
    "full_timesteps = pd.read_csv('./input/full_timesteps.csv')\n",
    "full_timesteps.Key=full_timesteps['SSS']+full_timesteps['TTT']\n",
    "full_timesteps['timestamp']= pd.date_range(first_timestep, periods = number_periods, freq =size_timestep)\n",
    "dict_timestamp=dict(zip(full_timesteps.Key, full_timesteps.timestamp))\n",
    "data['timestamp']=data['SSS']+data['TTT']\n",
    "data['timestamp']=data['timestamp'].map(dict_timestamp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copying and appending as many values as elements in TTT\n",
    "for market in market_timestep_proc:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional set declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccc = list(data.C.unique())\n",
    "rrr = list(data.RRR.unique())\n",
    "tech_type = list(data.TECH_TYPE.unique())\n",
    "commodity = list(data.COMMODITY.unique())\n",
    "fff = list(data.FFF.unique())\n",
    "sss = list(full_timesteps.SSS.unique())\n",
    "ttt = list(full_timesteps.TTT.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time step selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasons to investigate\n",
    "# season_names = ['S01', 'S07', 'S20', 'S24', 'S28', 'S38', 'S42', 'S43']\n",
    "# Make a list of every nth element of sss (1 <= nth <= number of elements in sss)\n",
    "nth = 1\n",
    "s = sss[0::nth]\n",
    " # Or select seasons by names\n",
    "# s = season_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terms to investigate\n",
    "# term_names = ['T005', 'T019', 'T033', 'T047', 'T061', 'T075', 'T089', 'T103', 'T117', 'T131', 'T145', 'T159']\n",
    "# Make a list of every nth element of ttt (1 <= nth <= number of elements in ttt)\n",
    "nth = 1\n",
    "t = ttt[0::nth]\n",
    "# Or select terms by name\n",
    "# t = term_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make output folder\n",
    "if not os.path.isdir('output'):\n",
    "    os.makedirs('output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make CurtailmentHourly folder\n",
    "if not os.path.isdir('output/' + output):\n",
    "    os.makedirs('output/' + output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make market folder\n",
    "for market in market_analysed:\n",
    "    if not os.path.isdir('output/' + output + '/'+ market +'/Country_wise'):\n",
    "        os.makedirs('output/' + output + '/'+ market +'/Country_wise')\n",
    "# Make country folder\n",
    "    if not os.path.isdir('output/' + output  + '/'+ market +'/Country_wise'):\n",
    "        os.makedirs('output/' + output  + '/'+ market  +'/Country_wise')\n",
    "    # Make country wise folders\n",
    "    for c in ccc:\n",
    "        if not os.path.isdir('output/' + output  + '/'+ market +'/Country_wise/' + c):\n",
    "            os.makedirs('output/' + output  + '/'+ market +'/Country_wise/' + c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data frames to plot\n",
    "data_plot = data[(data.SSS.isin(s)) & (data.TTT.isin(t))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot per year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in years:\n",
    "    spp_plot[data.SSS.isin([i])][ccc[:2]].plot(figsize=(16,9), lw=lw)\n",
    "    plt.ylim([0, y_limit])\n",
    "    plt.legend(loc=1)\n",
    "    plt.title('Curtailment in ' +  i)\n",
    "    plt.xlabel('Terms')\n",
    "    plt.xticks(t_marker, t_selected, rotation=45)\n",
    "    for x_pos in t_marker:\n",
    "        plt.axvline(x=x_pos, c='black', lw=6, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('output/pv_production/spp_' + i + '.png', compression=None)\n",
    "    # plt.show()\n",
    "    plt.close()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot example with several x axis\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax2 = ax1.twiny()\n",
    "\n",
    "# Add some extra space for the second axis at the bottom\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "ax1.set_xticks([1,2,4,5,7,8])\n",
    "ax1.set_xlim(0,9)\n",
    "ax1.set_xticklabels(('2015','2016','2015','2016','2015','2016'))\n",
    "ax2.spines[\"bottom\"].set_position((\"axes\", -0.15))\n",
    "ax2.xaxis.set_ticks_position(\"bottom\")\n",
    "ax2.spines[\"bottom\"].set_visible(True)\n",
    "ax2.set_xticks([1.5,4.5,7.5])\n",
    "ax2.set_xticklabels(('1','2','3'))\n",
    "ax2.set_xlim(0,9)\n",
    "\n",
    "b1 = np.random.randint(0,100,6)\n",
    "b2 = np.random.randint(0,100,6)\n",
    "b3 = np.random.randint(0,100,6)\n",
    "plt.bar(np.array([1,2,4,5,7,8])-0.4,b1,color='blue')\n",
    "plt.bar(np.array([1,2,4,5,7,8])-0.4,b2,color='orange',bottom=b1)\n",
    "plt.bar(np.array([1,2,4,5,7,8])-0.4,b3,color='yellow',bottom=b1+b2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
